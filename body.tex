\section{Introduction}

For the past few decades, both computing in America and
computer science in higher education have suffered from significant
underrepresentation of women, domestic students of color, and
students from lower socioeconomic backgrounds.  A wide variety of
projects have attempted to address these issues.  In spite of these
efforts only 17.9\% of bachelor's degrees in computer science are
awarded to students identified as female, 3.1\% to students identified
as Black or African-American, and 7.5\% to students identified as
Hispanic \cite{Taulbee2016}.  More work is needed.

Many issues are at play.  Some identify
a ``pipeline problem'', with members of these groups deciding
early on that they do not belong in computer science \cite{Gurer2002}.
Cheryan and Plaut \cite{Cheryan2010} suggest that stereotypes about
who ``does computing'' are one factor in this decision.  Guzdial
\cite{Guzdial2009} suggests that student beliefs that computing may
be ``irrelevant'' and ``asocial'' are also factors.  To help address
this problem, a variety of outreach activities have been developed
that target students early in their careers \cite{McGill2015,Decker2016}.

Over the past three years, our research team has explored the effect
of summer code camps on student interest and self-efficacy.  Rather
than employing the more common approaches to computing the emphasize
entertainment (e.g., robots, games, or Minecraft) \cite{DeWitt2017},
we emphasized meaningful uses of computing
\cite{arts-coding,dssg-sigcse-2018}, focusing primarily on issues
of computing for social good \cite{Goldweber2013}.  We hypothesize
that these more meaningful approaches will help build students'
self-efficacy and interest, particularly among those from groups
traditionally underrepresented in computing.

In this paper, we focus on a pair of middle-school camps offered in summer 2017
and 2018 in which campers explored computational
techniques related to the emerging field of data science and applied
their newly-developed skills to explore data sets relating to issues
of social good.
In section 2 of the paper, we describe the local context of the
camp, particularly the characteristics of our community and the
children who enrolled.  In section 3, we describe the design and
structure of the camp and provide additional detail about our
approaches to data science and computing for social good.  In section
4, we describe some changes we made  in the second year.  In section
5, we review data from camper surveys.  In section 6, we
conclude with a summary of the implications of the data and other
observations from the camp.

\section{Local context}

Our institution is in a rural community (approximately 9,000
residents) in a comparatively white state---91.4\% of the population identified as white
in the latest census.  Our community has a large population of
working poor: While the poverty rate in our county is over 30\%,
the unemployment rate is under 3\%.  Surrounding communities have
similar populations.

In designing the camp, we strove to address the particular concerns
of our community.  While we wanted to address the underrepresentation
of girls and students of color, we also wanted to make sure that
the camp was accessible to students of lower socioeconomic status.
Building these students' self-efficacy seems particularly important
as the opportunities presented by computing careers can make a huge
difference in their lives.  We used a variety of approaches to
support these campers, including free tuition for those on free
or reduced lunch programs\footnote{Unfortunately, because many feel
a stigma in our schools, many who would qualify for these
programs choose not to enroll.  The problem is most significant at
the high-school level, but it is also in play at the
middle-school level.  To help address that stigma, we relied only
on families' self-reports on the application form, and not on data
from the school district.}, providing meals and snacks for every
camper, subsidizing costs for all campers, and providing no-cost
options for early drop-off and late pick-up.

Because there are few educational enrichment activities available
to rural students, we drew students not only from our community,
but also from neighboring communities.  Some came from as far as
sixty miles away, suggesting that there are far too few such
opportunities for students in rural areas.

\section{Designing the camp}

Given the evidence of the value of computing for social good
approaches \cite{Goldweber2013,Goldweber2018}, our team's experience
with such activities in a prior project \cite{arts-coding}, and the
paucity of code camps that focus on computing for social
good \cite{DeWitt2017}, we chose to make
computing for social good a core theme of the camp.  
Adding a focus on data science incorporated a current and
discipline-spanning approach to computing.
The combination places our camp in a growing
``data science for social good'' (ds4sg) movement.\footnote{E.g.,
\url{https://dssg.uchicago.edu/}.}  
In the remainder of this section, we explore the themes and
associated camp design issues.

\subsection{Themes}

\subsubsection{Computing for social good}

As Goldweber \textit{et al.} \cite{Goldweber2013} suggest, many women
and students of color often avoid computing because they perceive
that computing is incapable of making a difference in their primary
areas of interest; such students often seek out
careers which have the potential of positively impacting their
communities.  Hence, unlike students who enter computing because
of a background in tinkering with computers or computational tasks,
these students need to see that computing can have a positive impact
on the world.  To encourage a more diverse discipline, we developed
the camp around the premise of ``computing for social good''
(CSG) \cite{Goldweber2015}, in which problems and context suggest ways
in which computing can have a real impact.  This
approach promoted the social relevance of computer science while
maintaining foundational programming concepts to give campers a
broader and more informed perception of computer science as a whole.

The direct application of the CSG methodology to the camp provided
much of its content. For example, Goldweber's ``Reuniting Families''
activity \cite{Goldweber2012} helped us teach campers about developing algorithms in the
context of societal disasters. We added a kinesthetic component to
that activity so that campers not only designed algorithms for
reuniting families, but also carried out each others' algorithms
in a large public space.  Our discussions about the current and
future roles of technology encouraged campers to explore computing
solutions to personal and societal issues.  Similarly, case studies
about weather patterns and car crashes favored an analytical approach
to national events.

\subsubsection{Data science}

The field of data science is growing rapidly; however,
its definition is tenuous, at best.  As one of the statistics faculty
noted when talking to us about possible ways to design a data science
curriculum, ``if you ask a dozen statisticians to define data
science, you'll get at least a half-dozen different answers''.
Since we were focusing on the computational aspects of data science,
we chose two primary ways of thinking about it: We taught campers
that data science is a field in which you gain insight from existing
data and that data science requires a series of replicable processes
(e.g., cleaning and wrangling) carried out by algorithms that data
scientists design and implement.  We focused on how the components
of algorithms (e.g., conditionals,  loops, and subroutines) can be
used to navigate a data set and how algorithms, along with visualization
routines, help one develop a broader understanding of data and share
that understanding with others.  We also discussed issues of data
cleaning, particularly algorithmic data cleaning (as opposed to
manual data cleaning).  In summary, we spent much of the week
teaching campers practical data organization and manipulation skills
so they could delve into data sets on their own.

Data science also supports many of our broader goals.  We saw an opportunity
further expand campers' perceptions of the capacity of computer
science and computing to help people solve problems and to make a
difference.  Our focus on diversifying computing also ties to similar
diversity goals in data science (e.g., \cite{Berman2015}).  Finally,
choosing a ``cutting edge'' topic can show our rural students that
they are able to engage with modern technologies.

\subsubsection{Combining the themes: Data science for social good}

At the time we were designing the first offering, we looked
for a short and pithy title that covered the two core aspects of the camp.
We settled on ``Data science for social good''.  At the time, a
new field with the same name was just beginning.  As in the cases of
both data science and computing for social good, it appears that there
are a wide variety of meanings associated with these terms.

In choosing our own approach to computing and data science for
social good, we identified a variety of approaches to help campers
understand how the tools of data science can have an impact.  For
example, although much of our focus was on campers writing scripts
to explore and visualize data, we also exposed them to mechanisms
for gathering environmental and other data.  The latter approach
helped them understand that they need not rely only on extant data
sets, but could also create their own.  Two sets of campers even
designed attitudinal surveys as part of their broader projects.

More generally, it appears campers came to understand that the
tools they were learning allowed them to identify or gather data
relevant to a social or societal situation of interest and transform
those data into a form in which they could make arguments relevant
to that situation and to affect opinions.  Focusing on computing
for social good also helped us avoid some of the stigma that may
be associated with data science, the sense that data science most
frequently means ``companies like Amazon and Facebook using their
data to sell you something''.  Like all projects in computing for
social good, our focus on ds4sg provided campers with the opportunity
to think about issues that mattered to them.

The CSG-Ed community suggests that there are four levels of CSG
activity \cite{Goldweber2018},

\begin{itemize}
\item \textit{Level 1}: The low hanging fruit: redefine an existing
  example/project with a CSG-Ed narrative.
\item \textit{Level 2}: Explicitly address a social good problem,
  though often in a simplified form.
\item \textit{Level 3}: A real world problem solved as an
  exercise.
\item \textit{Level 4}: A real world problem brought by stakeholders
  and with real world benefits rather than just an exercise
\end{itemize}

\noindent
Our approach is somewhat tangential, although perhaps similar to
level 2.  While they are not ``solving'' a problem, they are
explicitly addressing issues of social good, using a real data set
to provide useful analysis.

\input{curriculum.tex}

\subsection{Platforms and languages}

We took particular care in selecting applicable programming languages
and intuitive platforms. Other concerns 
included disparities in campers' prior programming experience and
their broad age range. For reasons which will be introduced and
elaborated in the following sections, we chose to base our camp in
three main languages: A pair of block-based languages and Python.

\subsubsection{BBC micro:bits---Hands-on activities with a block-based language}

BBC micro:bits are cheap, pocket-sized programmable computers
designed to act as an introductory interface for novice programmers.
Each individual micro:bit has a five-by-five grid of LEDs forming
a graphic interface, with two programmable buttons on either side
for user input.  The small size of the micro:bit might be deceiving
due to its numerous additional features including a built-in radio,
compass, and Bluetooth.\footnote{http://microbit.org/about/}

We introduced the micro:bit Blocks Editor early in the week because
it is an intuitive environment to introduce key programming
concepts such as loops, conditionals, and variables.\footnote{For
reasons that we do not quite understand, the block language does
not currently support subroutines.}  The block-based language 
supported novice learners.  It also gave students who had seen
a prior block-based language a chance to explore a different language
and extend their knowledge.  The micro:bits served as a visual counterpart
to indicate their progress, both successes and failures.  As one
of our primary goals of the camp was to increase the campers'
confidence in the subject matter, it was important to give the
campers a sense of accomplishment in a tangible and results-oriented
way early on.

\subsubsection{Jupyter Notebook---Programming like a data scientist}

As we had hoped, the Data Science for Social Good Camp drew in
campers who had not written much code before.  It also
appealed to campers who had learned block programming languages
in schools and wanted to move on to a higher-level language.  
We also wanted to empower both sets of campers to think
of themselves as real programmers.  For these reasons, we looked
to a platform that would permit campers to write realistic data
science code without too much overhead.  Python has long-standing
success as a text-based introductory language \cite{Guo2014} and
is widely used in the data science community.  We selected the
cloud-based Jupyter
Notebook environment\footnote{https://jupyter.org/documentation.html} 
because it is moderately friendly for novice users, supports
professional data scientists, and permitted campers 
to continue their work beyond the camp.\footnote{Many do not
necessarily have access to their own computers.  Those that receive
computers from the local school district are not permitted install
their own software.  A cloud-based solution permits them to continue
work in all situations.}

Jupyter Notebook is a popular Web-based platform for exploring and
analyzing data and is used by many professional data scientists.  Like
many modern computational systems for exploring data, it allows 
users to mix code, output, formatted text, and more into something
much like a scientist's notebook, but an interactive one.

Each camp worksheet typically took the form of a Jupyter Notebook
containing instructions, resources, and fill-in-the-blank partial
code.  These worksheets supplied campers with the means to practice
concepts relating to data science, including a final analysis of
their data.  Campers incorporated data from a csv or Excel document,
computed summary statistics, and created visualizations as prompted
by worksheets. The partial code provided examples
of syntax and common practice for code organization.  These served
as references for campers in later, more challenging exercises.

\subsubsection{Bridging the gap---From blocks to text}

To help campers adapt to a new programming environment, we designed
the camp to help them bridge the gap between the Block
Editor for micro:bits and Jupyter Notebooks, focusing less on
syntactic differences and more on the consistency of algorithmic
reasoning.  We scheduled the transition early in the week so that
campers would have more time to become comfortable with Python
before beginning their final projects.

We first used the BlockPy\footnote{https://think.cs.vt.edu/blockpy/index/}
Web-based Python Block Editor to familiarize campers with Python
\cite{Bart2017}.  BlockPy maintains the key infrastructure that we
had covered with campers in the micro:bits, such as loops, variables,
and conditionals, while introducing a split screen that displays
Python code alongside the block programs. In introducing BlockPy,
we had campers explore and compare the new interface to the old as
they looked for pieces of code that would help them solve a multi-part
word problem. This search allowed campers to reaffirm foundational
computer science concepts and develop their deductive skills.

We implemented a review of BBC micro:bits in the middle
of the week using the micro:bits Python Editor. During this activity,
the campers were given documentation and example code so that they
could code their micro:bits into compasses, radio communication
devices, and more. Reexamining the capabilities of micro:bits gave
campers an intermission from new material as well as the opportunity
to get more hands-on experience with Python.

While three languages in one week may seem like a lot, we found the
approach logical, campers progressed from a beginning block language 
that was straightforward but limited, through a more complex block
language, and on to a professional tool.  Because we tied ideas of
each language to the next, and because pairs of language shared
common characteristics, the transition seemed relatively smooth.  In
addition, our goal was not mastery, but exposure.

\subsection{Final projects}

Early on in designing curricula, we decided to end the week with a
larger, more personally driven final project, which we titled ``Final
Findings'' and introduced on the first day of camp.  This project
was intended to leave the campers with a tangible example of the
skills they had acquired over the course of the camp and a way to
connect to the material.

To enhance their sense of accomplishment, we concluded the camp
with project presentations in which pairs of campers presented the
data they chose to analyze, the significant data they discovered
through calculations, and the visualizations that they programmed.
After their hours of work on the data, campers readied their materials
for presentation to others.  We invited parents and community
members\footnote{An audience of roughly eighty people.} to those
presentations, which were a highlight of the week. which We discuss
the projects and presentations further below.

\subsection{Organizing topics and days}

In designing the camp, we considered both technical and
more conceptual outcomes; in addition to teaching tools
like loops and subroutines, we wanted campers to understand the
power that comes with writing programs and to realize that they
could write such programs.  We had also identified a necessary set
of skills for campers to complete the final projects in data
science.  As is the norm in designing such camps, we then considered
the natural flow of ideas, reflecting on the transition from
block-based languages to a text-based language and an appropriate
spiral approach that helped campers revisit topics in different
levels of depth.

While our primary focus was on computing topics, we knew from past
experience that this age group
would not learn well if they spent the day in front of the computer.
Hence, the camp schedule incorporated frequent ``away from computer''
activities including short breaks to play active and engaging games.
Snacks were offered during appropriate breaks before lunch. 

Moving the activities away from the computer did not mean that we
necessarily moved the campers away from thinking about core topics.
For example, one the first day of camp we moved to an outdoor
amphitheater to carry out the algorithms they had developed for
reuniting families after a disaster.  We also included CS Unplugged
\cite{csunplugged} activities to introduce Computer Science concepts
in a fun and active environment.  During afternoon breaks, we invited
faculty and students in the Computer Science department to introduce
campers to their research.

We also exposed campers to the broader view of ds4sg early and
repeatedly.  On many days, counselors presented a case study that
integrated new concepts with social good data. For example, our
second case study taught campers how to organize data about weather
changes in a way that would allow them to analyze it in Python.
Most of the last day was devoted to working on final projects,
getting them ready to present to their friends and family.

Table~\ref{table:curriculum} presents the curriculum for the
second year of camp.

\subsection{Extending the scavenger hunts}

We have traditionally made scavenger hunts a key part of our camps.
By exploring the science building, campers are exposed to
a wide range of scientists and science, including both female
scientists and scientists of color.  When they explore
the campus, they gain a sense of the resources associated with
a typical college.  One of our more successful
scavenger hunts involves the campers taking ``selfies'' throughout
the building.  For example, \textit{Take a picture of yourself with at
least four women scientists}, \textit{Take a picture of yourself with
three pieces of safety equipment}, \textit{Take a picture of yourself
in a lab coat},  and \textit{Take a picture of yourself with the person this
building is named for}.

For the second offering of the ds4sg camps, we enhanced two of the
scavenger hunts with data problems.  For one early scavenger hunt,
which we termed Scavenger:bits, we tasked campers with recording
data from throughout the science building.  Students worked in teams
to program the micro:bits to gather different kinds of data, raced
off to gather the data, and then returned to record it.  A second,
campus-wide, scavenger hunt tasked the campers with using
pre-programmed micro:bits to gather data at various locations across
campus and then to process it when they returned.

The Scavenger:bits activity, which we offered on the second
day of camp, exposed campers to the power of programming devices
to gather data.  It helped the campers transition into more serious
programming efforts.  It also helped the campers understand the
power of crowd-sourcing and the potentials for inconsistent data.
Since the campers entered the data in a common spreadsheet, they could
see both the additional scope of data that are possible in crowdsourcing
and also the variation that happens when different people gather
what should be the same data.

\section{Lessons from year one}

The camp has evolved in many ways between the two years.  The two
data-enhanced scavenger activities described above are one such
change.
Another major change we made had to do with the data sets that
campers used.  In the 2017 camp, we asked campers to find their
own data sets and convert them to CSV format.  At the same time,
we promised to finish any work they could not complete in a reasonable
amount of time.  In this endeavor, we were reminded of why many data
science classes provide students with a limited menu of data sets:
most groups of campers had difficulty locating data sets with
appropriate and useful data, even armed with the searching and
vetting tools we taught them.  Most groups found this experience
quite frustrating.  Thus, counselors spent extra time finding
data sets for some groups of campers as they had been unable to find
suitable data themselves.  Some groups also had to
change their topics depending on the availability of the data that
they intended to find.  For example, a group interested in studying
space debris ended up working with a data set on UFO sightings.
Luckily, campers were gracious and willing to adapt to these changes
and most tackled their new topics with vigor.

For the 2018 camp, we prepared a selected group of data sets for
the campers to use, including data sets on animals (wildlife trade,
threatened species), education, environment (carbon dioxide emission,
earth surface temperature, food waste), equity \& poverty (hate crimes,
homelessness, multidimensional poverty, stop and frisk), politics,
and broader society (public locations in our state, world happiness
report, representation of LGBT people on broadcast television).
The campers did not find these sets particularly limiting; most
were able to tie their interests to one or more of the data sets.
However, two groups decided to gather their own data (e.g., about
their fellow campers' political leanings and opinions on particular
data issues).  The surveys also revealed to the class some of the
risks of surveys; for example, since the surveys asked for age and
sex, the campers could immediately identify which surveys belonged
to the directors.\footnote{Mr. Director, it appears you forgot to
answer this question.}  That provided an illustrative example of
the responsibility of data scientists to consider the confidentiality
of their subjects.

We also streamlined parts of the curriculum, limiting their exposure
to micro:python, freeing time for deeper exposure to Jupyter.

In the first offering, we had assumed that campers would be excited
by the micro:bits, and they were, enough so that many parents
contacted us to find out how to get their own.  However, the campers,
by-and-large, told us that they were more excited by the work they
did in Python and Jupyter Notebook.  Although we can not pinpoint
the precise reason, it seems that they felt like they were doing
``real'' programming when they were working in Jupyter because the
environment they used matched that which working data scientists
use.  In contrast, our increased use of micro:bits for scavenger
hunts in 2018 seems to have heightened student interest without
diminishing their enthusiasm for Jupyter.

In the first offering, the rapid transition from block code to Python created
syntactic confusion.  Surprisingly, by spending less time on block
code in 2018 and more on Python, we were able to better ease this
transition.  That is, rather than covering issues like loops and
conditional deeply in the block language and then reintroducing
them in Python, we covered only the basics in the block language
and focused more strongly on them when we got to Python.  Perhaps
we should not have surprised about the difficulty campers had
transitioning between languages.  While there is an assumption that
language transfer is natural, some studies have recently challenged
that assumption (e.g., \cite{Chetty2012,Dann2012}).

In the first offering, we gave campers relatively few guidelines for their
presentations.  Most used the features of Jupyter Notebook to develop
presentations that mixed code, graphs, and text.  Others hand-drew
posters.  And a few gave only oral presentations.  During these
presentations, the campers demonstrated knowledge and commitment
to their topics, in addition to budding presentation skills. While
there were some technical difficulties, such as a Jupyter notebook
that would not load, the campers performed well and took setbacks
in stride.  However, some were clearly stressed by the openness of
the choice, and too few showed off their programming skills; while
a PowerPoint of charts can be compelling, it does
not reveal the underlying work.  Hence, for the 2018 camp, we asked
campers to present from their Jupyter notebooks and provided
tips for doing so.  It was clear from audience reactions that the
parents were surprised at the amount of code that the campers had
written.

\section{Exploring short-term outcomes}

Thirty-eight (38) students enrolled in the camp in 2017\footnote{That
was a bit more than we planned for.  But many campers showed up on
the first day with a friend in tow.} and twenty-five (25) students
enrolled in 2018.  Neither the length of the intervention nor the
comparatively small $n$ warranted a large-scale study.\footnote{
As Decker, McGill, and Settle suggest \cite{Decker2016,McGill2015},
longitudinal studies are more appropriate to consider the long-term
effects of such interventions.}  Nonetheless, gathering some
attitudinal data has shown value in the Georgia Computes! project
\cite{Bruckman2009} and we considered it equally useful to explore
some short-term effects using a similar approach.

In order to measure the campers' short-term change in self-efficacy
and coding confidence in a quantitative manner, we used pre-camp
and post-camp survey instruments based on upon the Georgia Computes!
instruments \cite{Bruckman2009} that ask students to respond to
various statements, such as ``I look like a computer scientist''
and ``I like the challenge of computing''.  For the 2017 camp, we
used  a seven-point Likert scale.  Based on our experience from the
2017 camp, for the 2018 camp we revised the instrument to use a
five-point Likert scale.  The questions appear in Figure~1; Note
that we changed question 14 in 2018 to provide more clarity for
students.

\begin{figure}
{\small
\begin{tabular}{r|l}
 1 & \textit{I look like a computer scientist.} \\
 2 & \textit{Boys can do computing.} \\
 3 & \textit{Girls can do computing.} \\
 4 & \textit{I know a lot about computing.} \\
 5 & \textit{I can become good at computing.} \\
 6 & \textit{I know more than my friends about computers.} \\
 7 & \textit{I like the challenge of computing.} \\
 8 & \textit{Computer science is cool.} \\
 9 & \textit{I feel comfortable using a computer.} \\
10 & \textit{I want to have a job in computing.} \\
11 & \textit{I want to learn more about computing.} \\
12 & \textit{Computer scientists are creative.} \\
13 & \textit{Solving problems is fun.} \\
14 & \textit{Computing is collaborative.} \\
14' & \textit{Computing involves people working together.} \\
15 & \textit{I like computing.} 
\end{tabular}
}
\caption{Survey statements}
\end{figure}

In fourteen out of the fifteen questions on the 2017 survey, we saw
an increase in the average response.  Eight of those changes were
statistically significant ($p < 0.05$). Notable positive changes
(with t-test results far below the threshold of significance)
occurred in the following questions: 1:\textit{I look like a computer
scientist}, which had a positive difference in average survey
response of approximately .94 points, 4:\textit{I know a lot about
computing}, which had a positive difference of approximately 1.2
points, and 6:\textit{I know more than my friends about computers},
with a positive difference of 1 point.  It seems that campers,
although somewhat apprehensive of their own potential at the start
of the project, found themselves more sure of their abilities, not
only in comparison with their peers outside of the project, but
also as independent thinkers.

In the 2018 data, we also saw especially significant short-term
growth ($p < 0.01$) in questions 1, 4, and 6.  This year, we also
saw similarly significant growth ($p < 0.01$) in question
14:\textit{Computing involves people working together}\footnote{It
appears our choice of wording was important!} and 15:\textit{I like
computing}.

%Our surveys also included fields for ethnicity and gender, which
%we hoped to use to investigate the differences of growth in
%self-efficacy between different identity groups in early computer
%science exposure. Due to the low representation of students of
%color, we were unable to draw informative statistics on the growth
%of the minority ethnic-identity groups within our project. We were,
%nontheless, able to investigate some differences in the growth of
%female and male campers.

A few trends appeared when looking at the pre-camp and post-camp
averages for female campers versus the averages for male campers
in the 2017 data.  In both pre-camp and post-camp surveys, female
campers tended to have a larger increase in self-efficacy than the
male campers. This intuition is supported in the case of questions
2:\textit{Boys can do computing}, 3:\textit{Girls can do computing},
7:\textit{I like the challenge of computing}, 9:\textit{I feel
comfortable using a computer}, 10:\textit{I want to have a job in
computing}, and 14:\textit{Computing is collaborative}, where the
change in the female campers' responses yielded significant results
($p < 0.05$) and the change in male campers' responses did not ($p
> 0.05$). Only in question 5 did the male campers' difference in
average response yield a significant change while the female campers'
responses did not.

It seems that the curricula of this project had a more significant
short-term effect on our female campers, which is in keeping with Goldweber
\textit{et al.}'s analysis \cite{Goldweber2013}.  The only negative
difference in averages in the female campers' responses was with
question 11:\textit{I want to learn more about computing}, which,
although discouraging to note, did not yield significant results
when running a two-tail t-test (null hypothesis, $p < 0.01$).

These initial results suggest that, at least for the short term,
we have and fulfilled our intent to make the concepts of computer
science more accessible to youth who perhaps do not identify with
the statement ``I look like a computer scientist''. The even more
significant increase in confidence in our female campers is an
especially encouraging outcome. Our results give us hope that the
campers left inspired, and may collaborate with peers outside of
the project to continue their education in computer science.

\section{Conclusion}

Although many middle-school outreach activities focus on students'
perceived interests, such as video games or ``exciting'' technologies,
our experiences suggest that computing for social good
provides a platform for helping students grow in self-efficacy and
interest.

As the assessment suggests, the camp was generally successful in
making a positive short-term difference in students' sense of who
can ``do'' computing and in their own self-efficacy and interest.
While we were saddened to see that the female campers often began
the camp with lower responses on most questions, we were encouraged
to see their gains as higher than the male campers'.

The projects were central to the success of the camp and they
provided some of the greatest benefits.  As campers gained
familiarity with data science tools, they became more comfortable
with the idea of a final project on a subject of their choosing.

We have also found that while campers can be intimidated by a
text-based programming language and a professional programming
environment, they also feel empowered and gain additional self-efficacy
in using such an environment.  Our informal conversations with the
campers suggest that the approach is worth investigating further.
Resources from the camp, including curriculum, instructor guides,
and presentations are available at \url{https://codecamp.sites.grinnell.edu/dataforsocialgood/}.
